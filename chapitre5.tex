%!TEX root = main.tex
% \begin{figure}[htb]
% \begin{center}
% %optional pour enlever un peu d'espace blanc de votre silhouette
% %\vspace{-.3cm}
%  %\includegraphics[keepaspectratio,width=0.5\textwidth]{fig/nomde}
% % analoog
% %\vspace{-0.6cm}
%  % \caption{ici un logo}
%  % \label{fig:ruglogo}
% %analoog
% %\vspace{-.6cm}
% \end{center}
% \end{figure}

% Utilisation du template
% \cite(reference à citer)
% \ref(figure à référencer)

\chapter{Axes de Recherches : WGAN}

\paragraph*{Introduction : } Avec les différents résultats obtenus par nos premiers GAN, nous avons pu tirer, entre autres, deux conclusions importantes. Le GAN manque cruellement de stabilité, (par exemple un petit changement de paramètre l'empêche de converger correctement), et de métriques pertinentes, c'est à dire que les scores des générateurs et des discriminateurs n'ont pas d'interprétations en termes de progrès de la qualité d'image perçue.\\
Les chercheurs se sont beaucoup attardés depuis 2016 sur la première question, en comparant par exemple les différents optimiseurs possible \cite{optimiser}, le deuxième point est moins souvent abordés. \\
L'article de 2017 Wasserstein GAN \cite{wgan} propose une méthode qui, en s'éloignant légèrement de la philosophie original du papier de Goodfellow \cite{Goodfellow-et-al-2016}, tente d'apporter une réponse à ces deux questions, avec en particulier une métrique pertinente.

\section{Problématique de la descente de gradient simultanée}

L'article de Goodfellow semble démontrer la convergence du système GAN, cependant la mise en œuvre montre que cette convergence n'est pas aussi évidente à obtenir. En effet, il semblerait que la stratégie de descente de gradient de l'algorithme de GAN ne permettent pas d'assurer cette convergence. Le blog inFERENCe \cite{conservative-field} décrit une partie du problème en se basant sur l'article The Numerics of GANs \cite{numerics-gan}.

Ces articles montrent que la descente de gradient simultanée n'est pas simplement une double descente de gradient, mais une descente de gradient dans un champ vectoriel. l'algorithme de GAN effectue l'optimisation suivante : 
\[x_{t+1} \leftarrow x_t + h v(x_t) \text{ avec } v(x) = \left(\begin{matrix}\frac{\partial}{\partial\theta}f(\theta, \phi)\\\frac{\partial}{\partial\phi}g(\theta, \phi)\end{matrix}\right).\]

$f$ et $g$ étant respectivement les fonctions de coût du Discriminateur et du Générateur. Cependant on constate 2 problèmes, d'une part l'algorithme basé sur la théorie des jeux, qui consiste à faire "jouer" tour à tour le Discriminateur et le Générateur pour optimiser ses paramètres ne consiste qu'en une approximation de la simultanéité de la descente, d'autre part il n'y a aucune preuve que le champ vectoriel $x$ dans lequel l'on se déplace possède des propriétés conservatives. En particulier rien ne garantie que le rotationnel soit nul, ce qui implique que la descente de gradient ne soit pas garantie d'aller vers un minimum, même local !

% insérér gif ou screen de la descente qui tourne en rond

On est donc à la recherche d'une autre approche qui contournerait ce problème.



\section{L'approche Wasserstein GAN}

Le papier Wasserstein GAN \cite{arjovsky_wasserstein_2017}, propose une autre approche que celle de la théorie des jeux.

Il s'agit de calculer une divergence entre distribution afin de se servir de cette métrique pour faire l'apprentissage de l'une sur l'autre. Au premier abord cette approche ne semble pas si différente de l'approche de Goodfellow, mais elle en est sensiblement différente. Dans l'approche précédente, l'on tente de minimiser la divergence entre deux distribution par un algorithme utilisant 2 réseaux de neurones, cependant, nous n'avons jamais accès à cette divergence (que l'on utilise des fonctions d'erreur pour approcher la KL-divergence ou une autre), et comme nous l'avons montré précédemment la convergence n'est pas réellement assurée. 

L'idée du papier Wasserstein GAN est de calculer explicitement une divergence entre deux ensemble. Cela n'est pas une question simple, comme nous avons pu le voir au chapitre 1. En effet nous n'avons généralement pas accès à la distribution $p_{\text{réel}}$ mais uniquement à un échantillon tiré de cette distribution. \\ Cependant il apparait possible de calculer une divergence entre deux ensemble à l'aide des réseaux de neurones. Cela est possible en tout cas avec la divergence de Wasserstein, comme le montre ce papier, nous allons revenir sur les étapes de raisonnements.

L'objectif est de rapprocher 2 distributions en utilisant la métrique de Wasserstein à l'ordre 1. Celle-ci s'écrit :
\[
W(\mathbb{P}_r, \mathbb{P}_g)= \underset{\gamma \in (\mathbb{P}_r, \mathbb{P}_g)}{\text{inf}} \mathbb{E}_{(x,y)\sim\gamma} \left[ ||x-y||\right]
\]
On peut la nommer également distance Earth-Mover, c'est à dire distance du déplacement de terre. En effet cette métrique calcul l'effort à faire pour passer d'une distribution à l'autre. Par exemple si l'on a deux terrain contenant des tas de terre, la hauteur de terre en un point représente la densité de probabilité à cette endroit, le volume complet de terre étant le même (cela représente l'intégrale sur le terrain), alors la distance EM entre les deux terrains est l'effort minimal que l'on peut faire pour déplacer la terre de l'un des terrains pour le faire ressembler à l'autre. Il y a une infinité de façon de déplacer la terre, avec des efforts différents, la distance de Wasserstein, C'est le coût en utilisant le plan de transport optimal. Cela se traduit également en terme de probabilité jointes, pour une approche plus mathématique. 

L'idée d'utiliser cette divergence de Wasserstein provient des propriétés mathématique qui devrait la rendre plus pertinente pour l'apprentissage des GANs, le détails se trouve dans se papier, mais cela se résume à dire que cette divergence donne plus d'information que la KL-Divergence et ses dérivées (Jensen-Shannon, etc) en étant entre autre bien défini lorsque les supports de distribution sont disjoints et en étant moins souvent constant, avec donc des gradients non nuls et plus adapté à l'apprentissage.

On ne peut toujours pas se servir de cette divergence, mais un théorème (la dualité Kantorovich-Rubinstein \cite{optimal-transport}) permet d'obtenir une nouvelle forme de cette divergence :
\[
W(\mathbb{P}_r, \mathbb{P}_g) = \underset{||f||_L<1}{\text{sup}}\mathbb{E}_{x\sim\mathbb{P}_r}\left[f(x)\right] - \mathbb{E}_{x\sim\mathbb{P}_g}\left[f(x)\right]
\]
Vous pouvez en voir une preuve simplifié sur le blog de Vincent Hermann \cite{preuve-wgan}
On se retrouve alors à calculer un sup sur un ensemble de fonction (les fonctions 1-Lipschitziennes), et cela est pratique car c'est justement ce que permet de faire un réseau de neurones : Simuler des fonctions que l'on optimise par rapport à un paramètre ! On construit un réseau qui joue le rôle des fonctions f, on a donc des paramètres $W$ à optimiser pour trouver la valeur maximum. Il ne reste qu'à s'assurer que les réseaux de neurones peuvent garantir le caractère 1-Lipschitzien.

Une méthode pour s'assurer de cette propriété est de restreindre les poids dans un intervalle [-c, c] (on parle de weight-clipping). Cependant on obtient un caractère K-Lipschitzien, avec un K inconnu. (En terme de preuve, il suffit de voir que des matrice avec ses propriétés sont toutes K-Lipschitziennes avec un même K.) cela nous assure que l'on peut calculer non pas $W(\mathbb{P}_r, \mathbb{P}_g)$ mais $K*W(\mathbb{P}_r, \mathbb{P}_g)$, mais le K étant fixe tout au long de l'apprentissage cela reste une métrique pertinente. 

Nous avons donc la possibilité avec un réseau de neurone de calculer la métrique de Wasserstein et nous allons pouvoir nous en servir pour l'apprentissage d'un générateur

\section{Mise en œuvre}

Fort de cette métrique que l'on peut calculer, nous allons pouvoir mettre en place un algorithme d'apprentissage pour la génération d'image.

Tout d'abord nous avons toujours besoin de deux réseaux, l'un pour la génération, dont le rôle est strictement identique au générateur qui on pu être vu avant, et l'autre pour le calcul de la divergence de Wasserstein. Ce second réseau est appelé critique (plutôt que Discriminateur) par la littérature. Attention, le critique simule une fonction $f$ qui est telle que $\mathbb{E}_{x\sim\mathbb{P}_r}[f(x)] - \mathbb{E}_{x\sim\mathbb{P}_g}[f(x)] $ soit la sortie d'un batch contenant des vrais images et des images de synthèses, c'est à dire que $f(x)$ et $f(G(z))$ n'ont pas de sens contrairement aux $D(x)$ et $D(G(z))$ vu précédemment. 
Afin que le critique calcule effectivement $W(\mathbb{P}_r, \mathbb{P}_g)$, il est nécessaire de faire converger les paramètres du critique pour obtenir $f_{\text{max}}$. Une fois $W(\mathbb{P}_r, \mathbb{P}_g)$ obtenu, on peut chercher à le minimiser pour faire progresser le générateur, on effectue donc une descente de gradient à partir de ce coût. Cependant on a en fait $f_{\text{max}}(\mathbb{P}_r, \mathbb{P}_g, x)$, c'est à dire que $f_max$ dépend des distributions à un instant donné, par conséquent après une itération on obtient:
 \[\mathbb{E}_{x\sim\mathbb{P}_r}[f_\text{max}((\mathbb{P}_r, \mathbb{P}_g), x)] - \mathbb{E}_{x\sim\left(\mathbb{P}_g+\Delta\mathbb{P}_g\right)}[f_\text{max}((\mathbb{P}_r, \mathbb{P}_g), x)] \]

Ce qui est différent de :
 \[ \mathbb{E}_{x\sim\mathbb{P}_r}[f_\text{max}((\mathbb{P}_r, \left(\mathbb{P}_g+\Delta\mathbb{P}_g\right)), x)] - \mathbb{E}_{x\sim \mathbb{P}_g}[f_\text{max}((\mathbb{P}_r, \left(\mathbb{P}_g+\Delta\mathbb{P}_g\right)), x)] = W(\mathbb{P}_r, \mathbb{P}_g+\Delta\mathbb{P}_g)\]

 Il faut donc à chaque itération refaire converger le critique pour garantir que l'on a bien la fonction $f_max$ correspondant à la distribution $\mathbb{P}_g$ courante (on a en effet $\mathbb{P}_r$ fixe tout du long).

 L'algorithme se dessine alors simplement :
 \begin{itemize}
 \item Faire converger le critique en maximisant la quantité $\mathbb{E}_{x\sim\mathbb{P}_r}[f(x)] - \mathbb{E}_{x\sim\mathbb{P}_g}[f(x)] $
 \subitem - Récuperer un batch d'images réelles
 \subitem - Générer une batch d'images virtuelles
 \subitem - Calculer $\mathbb{E}_{x\sim\mathbb{P}_r}[f(x)] - \mathbb{E}_{x\sim\mathbb{P}_g}[f(x)] $
 \subitem - Rétro-propager dans le critique
 \subitem - Recommencer jusqu'à convergence
 \item Faire évoluer le générateur en minimisant la quantité $\mathbb{E}_{x\sim\mathbb{P}_r}[f(x)] - \mathbb{E}_{x\sim\mathbb{P}_g}[f(x)] $
 \subitem - Générer un batch d'images virtuelles
 \subitem - Calculer $- \mathbb{E}_{x\sim\mathbb{P}_g}[f(x)] $
 \subitem - Il n'est pas nécessaire d'effectuer le calcul pour de vrais images, car elles ne servent pas dans la retro-propagation dans le générateur
 \subitem - Rétro-propager dans le critique sans le modifier
 \subitem - Rétro-propager dans le générateur
 \item Recommencer les 2 étapes jusqu'à convergence du générateur
 \end{itemize}

 On notera dans cette algorithme deux zones floues qui sont les ré-itération "Jusqu'à la convergence". En effet il est particulièrement difficile de s'assurer qu'on a bien converger, ou plutôt de savoir que l'on a converger suffisamment. Comme dans tout les algorithmes de se genre, il y a un trade-off entre le temps de calcul, et une précision parfaite.

 Pour la convergence du critique, l'article Wasserstein \cite{arjovsky_wasserstein_2017} suggère de le faire converger de façon certaine au début, i.e, de s'assurer que l'on calcule bien $W ( \mathbb{P}_r, \mathbb{P}_g ) $ avec $\mathbb{P}_g$ étant du bruit avant tout apprentissage. Pour cela on effectue longuement la première étape avant toutes choses. Puis on peut estimer qu'une itération de descente de gradient sur le générateur change peu se dernier, et par une hypothèse de continuité sur la distance de Wasserstein (qui semble justifié si l'on considère cette distance comme la distance Earth-Mover) on peut estimer qu'il faudra peut d'itération de montée de gradient pour faire de nouveau converger "suffisamment" le critique.

 Pour la convergence du générateur, on en revient aux problèmes classiques du GAN qui consiste à se demander à quelle moment le générateur est suffisamment performant, on y reviendra dans la partie suivante.

 \section{Réflexion sur l'approche}

 \subsection{Utilisation de la distance de Wasserstein pour évaluer un générateur}
 \subsection{Problème du caractère Lipschitziens des réseaux de neurones}
 \subsection{Peut-on adapter la logique de cette algorithme à d'autre méthode ?}